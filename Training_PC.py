from __future__ import print_function
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.feature_extraction.text import CountVectorizer
import numpy as np
import pickle
import matplotlib.pyplot as plt


Bengin_sentences = pickle.load(open("BMsave/Bengin_PC_OPCodeList", "r+b"))
Malware_sentences = pickle.load(open("BMsave/Malware_PC_OPCodeList", "r+b"))
PC_vocabulary = pickle.load(open("BMsave/PC_vocabulary", "r+b"))

Y_train = []
for i in range(len(Bengin_sentences)):
    Y_train.append([1, 0])
for i in range(len(Malware_sentences)):
    Y_train.append([0, 1])

vectorizer = CountVectorizer(min_df=0, lowercase=False, vocabulary=PC_vocabulary)
# for i in PC_vectorizer.vocabulary_:
#     print(i)

X_train = np.array(vectorizer.transform(Bengin_sentences + Malware_sentences).toarray(), dtype=np.float64)

min_max_scaler = MinMaxScaler()
X_train = min_max_scaler.fit_transform(X_train)
# X_test = min_max_scaler.fit_transform(X_test)
# Y_train = np.transpose(Y_train)
# Y_test = np.transpose(Y_test)

# define placeholder for inputs to network
inputLayer = tf.placeholder(tf.float32, [None, 187])
hiddenWeight = tf.Variable(tf.truncated_normal([187, 30], mean=0, stddev=0.1), name="hiddenWeight")
hiddenBias = tf.Variable(tf.truncated_normal([30]), name="hiddenBias")
hiddenLayer = tf.add(tf.matmul(inputLayer, hiddenWeight), hiddenBias)
hiddenLayer = tf.nn.sigmoid(hiddenLayer)
outputWeight = tf.Variable(tf.truncated_normal([30, 2], mean=0, stddev=0.1))
outputBias = tf.Variable(tf.truncated_normal([2], mean=0, stddev=0.1))
outputLayer = tf.add(tf.matmul(hiddenLayer, outputWeight), outputBias)
outputLayer = tf.nn.sigmoid(outputLayer)
outputLabel = tf.placeholder(tf.float32, shape=[None, 2])


# the error between prediction and real data
loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=outputLabel, logits=outputLayer))
optimizer = tf.train.AdamOptimizer()
target = optimizer.minimize(loss)

sess = tf.Session()
sess.run(tf.global_variables_initializer())

acc = []
LossList = []
for i in range(5000):
    x = X_train
    y = Y_train
    sess.run(target, feed_dict={inputLayer: x, outputLabel: y})
    if (i+1) % 20 == 0:
        corrected = tf.equal(tf.argmax(outputLabel, 1), tf.argmax(outputLayer, 1))
        accuracy = tf.reduce_mean(tf.cast(corrected, tf.float32))
        accuracyValue, lossValue = sess.run([accuracy, loss], feed_dict={inputLayer: x, outputLabel: y})
        print(i+1, 'train set accuracy:', accuracyValue)
        acc.append(accuracyValue)
        LossList.append(lossValue)

W = tf.get_default_graph().get_tensor_by_name('hiddenWeight:0').eval(session=sess)
pickle.dump(W, open('BMsave\PC_Weights', 'w+b'))
fig = plt.figure()
plt.plot(range(250), acc)
plt.xlabel("x")
plt.ylabel("loss")
plt.show()


