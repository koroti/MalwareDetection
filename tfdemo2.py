from __future__ import print_function
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.feature_extraction.text import CountVectorizer
import numpy as np
import pickle
import matplotlib.pyplot as plt
import random

def compute_accuracy(v_xs, v_ys):
    global prediction
    y_pre = sess.run(prediction, feed_dict={xs: v_xs})
    correct_prediction = tf.equal(tf.argmax(y_pre, 1), tf.argmax(v_ys, 1))
    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
    result = sess.run(accuracy, feed_dict={xs: v_xs, ys: v_ys})
    return result

Bengin_sentences = pickle.load(open("BMsave/Bengin_Test_OPCodeList", "r+b"))
Malware_sentences = pickle.load(open("BMsave/Malware_Test_OPCodeList", "r+b"))
Android_vocabulary = pickle.load(open("BMsave/Android_vocabulary", "r+b"))

Y = []
for i in range(len(Bengin_sentences)):
    Y.append([1, 0])
for i in range(len(Malware_sentences)):
    Y.append([0, 1])

vectorizer = CountVectorizer(min_df=0, lowercase=False, vocabulary=Android_vocabulary)
# for i in PC_vectorizer.vocabulary_:
#     print(i)

X_train, X_test, Y_train, Y_test = train_test_split(np.array(vectorizer.transform(Bengin_sentences + Malware_sentences).toarray(), dtype=np.float64), Y, test_size=0.75, random_state=1005)

min_max_scaler = MinMaxScaler()
X_train = min_max_scaler.fit_transform(X_train)
X_test = min_max_scaler.fit_transform(X_test)
# Y_train = np.transpose(Y_train)
# Y_test = np.transpose(Y_test)

# define placeholder for inputs to network
xs = tf.placeholder(tf.float32, [None, 61])
ys = tf.placeholder(tf.float32, [None, 2])
PC_Weights = pickle.load(open("BMsave\Public_Weights", "r+b"))

Init_Weights = []
for i in range(61):
    if i in range(36):
        Init_Weights.append(PC_Weights[i])
    else:
        temp = []
        for j in range(2):
            temp.append(random.normalvariate(0, 1))
        Init_Weights.append(temp)

Init_Weights = np.asarray(Init_Weights, dtype=np.float32)
tensorval = tf.constant(value=Init_Weights, dtype=tf.float32)
# add output layer
with tf.name_scope("Model"):
    # add one more layer and return the output of this layer
    # Weights = tf.Variable(tensorval, name="W")
    Weights = tf.Variable(tf.random_normal([61, 2]), name="W")
    biases = tf.Variable(tf.zeros([1, 2]) + 0.1, name="b")
    Wx_plus_b = tf.matmul(xs, Weights) + biases
    prediction = tf.nn.softmax(Wx_plus_b,)

# the error between prediction and real data
cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction), reduction_indices=[1]))       # loss
train_step = tf.train.GradientDescentOptimizer(3.5).minimize(cross_entropy)

sess = tf.Session()

init = tf.global_variables_initializer()
sess.run(init)
acc = []
x = range(100)

for i in range(1000):
    batch_xs, batch_ys = X_train, Y_train
    sess.run(train_step, feed_dict={xs: batch_xs, ys: batch_ys})
    # if i % 50 == 0:
    #     print("acc =", compute_accuracy(X_test, Y_test))
    if (i+1) % 10 == 0:
        acc.append(compute_accuracy(X_test, Y_test))
# print(tf.trainable_variables())
# W = tf.get_default_graph().get_tensor_by_name('Model/W:0').eval(session=sess)
# print(W)
fig = plt.figure()
plt.plot(x, acc)
plt.xlabel("x")
plt.ylabel("acc")
plt.show()
for i in acc:
    print(i)


