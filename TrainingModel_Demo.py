from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import MinMaxScaler
from sklearn.linear_model import LogisticRegression
from keras.models import Sequential
from keras import layers
from keras.callbacks import TensorBoard
from keras.preprocessing.text import Tokenizer
import keras

import numpy as np
import pickle
import matplotlib.pyplot as plt
import datetime

plt.style.use('ggplot')

def plot_history(history):
    acc = history.history['acc']
    val_acc = history.history['val_acc']
    loss = history.history['loss']
    val_loss = history.history['val_loss']
    x = range(1, len(acc) + 1)

    plt.figure(figsize=(12, 5))
    plt.subplot(1, 2, 1)
    plt.plot(x, acc, 'b', label='Training acc')
    plt.plot(x, val_acc, 'r', label='Validation acc')
    plt.title('Training and validation accuracy')
    plt.legend()
    plt.subplot(1, 2, 2)
    plt.plot(x, loss, 'b', label='Training loss')
    plt.plot(x, val_loss, 'r', label='Validation loss')
    plt.title('Training and validation loss')
    plt.legend()
    plt.show()

def Logistic(X_train, Y_train, X_test, Y_test):
    LR = LogisticRegression(solver='liblinear')
    LR.fit(X_train, Y_train)
    score = LR.score(X_test, Y_test)
    print("Accuracy:", score)
    print(X_train.shape, Y_train.shape)

def RandomForest(X_train, Y_train, X_test, Y_test):
    clf = RandomForestClassifier(n_estimators=10, criterion='gini')
    clf.fit(X_train, Y_train)
    score = clf.score(X_test, Y_test)
    print("Accuracy:", score)
    print(X_train.shape, Y_train.shape)

def KerasBulid(X_train, Y_train, X_test, Y_test):
    input_dim = X_train.shape[1]
    model = Sequential()
    model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))
    model.add(layers.Dense(1, activation='sigmoid'))
    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
    localtime = datetime.datetime.now().strftime('%Y_train%m%d_%H%M%S')
    tbCallBack = TensorBoard(
        log_dir='D:/GraduationProject/Code/TensorBoard/log_' + localtime, # log 目录
        histogram_freq=0, # 按照何等频率（epoch）来计算直方图，0为不计算
        batch_size=32, # 用多大量的数据计算直方图
        write_graph=True, # 是否存储网络结构图
        write_grads=True, # 是否可视化梯度直方图
        write_images=True, # 是否可视化参数
        embeddings_freq=0,
        embeddings_layer_names=None,
        embeddings_metadata=None
    )
    history = model.fit(
        X_train,
        Y_train,
        batch_size=50,
        epochs=2000,
        verbose=1,
        validation_data=(X_test, Y_test),
        callbacks=[tbCallBack]
    )

    loss, accuracy = model.evaluate(X_train, Y_train, verbose=False)
    print("Training Accuracy: {:.4f}".format(accuracy))
    loss, accuracy = model.evaluate(X_test, Y_test, verbose=False)
    print("Testing Accuracy:  {:.4f}".format(accuracy))
    # plot_history(history)

Bengin_sentences = pickle.load(open("BMsave/Bengin_Train_OPCodeList", "r+b"))
Malware_sentences = pickle.load(open("BMsave/Malware_Train_OPCodeList", "r+b"))

Y = np.array(([0]*len(Bengin_sentences) + [1]*len(Malware_sentences)), dtype=np.float64)

vectorizer = CountVectorizer(min_df=0, lowercase=False)
vectorizer.fit(Bengin_sentences + Malware_sentences)
# for i in PC_vectorizer.vocabulary_:
#     print(i)

X_train, X_test, Y_train, Y_test = train_test_split(np.array(vectorizer.transform(Bengin_sentences + Malware_sentences).toarray(), dtype=np.float64), Y, test_size=0.5, random_state=1000)

min_max_scaler = MinMaxScaler()
X_train = min_max_scaler.fit_transform(X_train)
X_test = min_max_scaler.fit_transform(X_test)


# tokenizer = Tokenizer()
# tokenizer.fit_on_texts(Bengin_train_sentences + Malware_train_sentences)
#
# keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences(Bengin_train_sentences + Malware_train_sentences))

# Logistic(X_train, Y_train, X_test, Y_test)
# RandomForest(X_train, Y_train, X_test, Y_test)
KerasBulid(X_train, Y_train, X_test, Y_test)
